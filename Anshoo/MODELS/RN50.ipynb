{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RN50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "isDuAYKHXX1F"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9ZUAauFYAEW"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/main2'\n",
        "batch_size = 32\n",
        "img_height = 150\n",
        "img_width = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sc2pwefYD0m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c67df0-8064-4673-e643-0c1e790f60de"
      },
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 17652 files belonging to 7 classes.\n",
            "Using 14122 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdk7VLvOYH9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93219b1b-f378-4453-e0d4-11eaa7020eda"
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 17652 files belonging to 7 classes.\n",
            "Using 3530 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36p3QETnYRUs"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py-H_eF5YU3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f33135c6-e846-4fd7-ddf1-f7b24ec2555e"
      },
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixels values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI8HZXSLYXYy"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuSFuaDcYaAc"
      },
      "source": [
        "num_classes = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHAKI0yhYarR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e74289a-47fd-457f-cece-efbff902e011"
      },
      "source": [
        "RN50 = ResNet50(weights= 'imagenet', include_top=False, input_shape= (img_height,img_width,3))\n",
        "input = RN50.output\n",
        "input = layers.GlobalAveragePooling2D()(input)\n",
        "# input = layers.Dropout(0.2)\n",
        "fpred = layers.Dense(num_classes, activation = 'softmax')(input)\n",
        "model = tf.keras.models.Model(inputs = RN50.input, outputs = fpred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXQqz5mjalng"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7LdK0yLgp83"
      },
      "source": [
        "class CustomCallbacks(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('val_accuracy')>0.965):\n",
        "        print(\"\\n 96% val_acc reached\")\n",
        "        self.model.stop_training = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-GR5G1PdtJ1"
      },
      "source": [
        "!mkdir -p /content/drive/MyDrive/Model/RN50_1/cp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUuFsy6gbSgJ"
      },
      "source": [
        "checkpoint_filepath = '/content/drive/MyDrive/Model/RN50_1/cp/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8JrXt0abLrZ"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeuSp3ZmRu1R",
        "outputId": "eba0298d-675a-48b1-dfba-1f27932c02bc"
      },
      "source": [
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=30,\n",
        "  callbacks = [model_checkpoint_callback]\n",
        ")\n",
        "\n",
        "model.save('/content/drive/MyDrive/Model/RN50_1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "442/442 [==============================] - 5126s 12s/step - loss: 1.3544 - accuracy: 0.5125 - val_loss: 1.0207 - val_accuracy: 0.6969\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Model/RN50_1/cp/assets\n",
            "Epoch 2/30\n",
            "442/442 [==============================] - 107s 241ms/step - loss: 0.4562 - accuracy: 0.8352 - val_loss: 0.6917 - val_accuracy: 0.7756\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Model/RN50_1/cp/assets\n",
            "Epoch 3/30\n",
            "442/442 [==============================] - 107s 241ms/step - loss: 0.2933 - accuracy: 0.8962 - val_loss: 0.7186 - val_accuracy: 0.7612\n",
            "Epoch 4/30\n",
            "442/442 [==============================] - 106s 241ms/step - loss: 0.1886 - accuracy: 0.9324 - val_loss: 0.6252 - val_accuracy: 0.7756\n",
            "Epoch 5/30\n",
            "442/442 [==============================] - 107s 241ms/step - loss: 0.1469 - accuracy: 0.9478 - val_loss: 1.1410 - val_accuracy: 0.7116\n",
            "Epoch 6/30\n",
            "442/442 [==============================] - 107s 242ms/step - loss: 0.1055 - accuracy: 0.9635 - val_loss: 0.3625 - val_accuracy: 0.8946\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Model/RN50_1/cp/assets\n",
            "Epoch 7/30\n",
            "442/442 [==============================] - 107s 242ms/step - loss: 0.0992 - accuracy: 0.9663 - val_loss: 0.5445 - val_accuracy: 0.8584\n",
            "Epoch 8/30\n",
            "442/442 [==============================] - 107s 242ms/step - loss: 0.0834 - accuracy: 0.9720 - val_loss: 0.4042 - val_accuracy: 0.8963\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Model/RN50_1/cp/assets\n",
            "Epoch 9/30\n",
            "442/442 [==============================] - 107s 242ms/step - loss: 0.0728 - accuracy: 0.9733 - val_loss: 0.3509 - val_accuracy: 0.8989\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Model/RN50_1/cp/assets\n",
            "Epoch 10/30\n",
            "442/442 [==============================] - 107s 241ms/step - loss: 0.0914 - accuracy: 0.9721 - val_loss: 0.6788 - val_accuracy: 0.7884\n",
            "Epoch 11/30\n",
            "442/442 [==============================] - 107s 241ms/step - loss: 0.0599 - accuracy: 0.9799 - val_loss: 0.1978 - val_accuracy: 0.9459\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Model/RN50_1/cp/assets\n",
            "Epoch 12/30\n",
            "442/442 [==============================] - 107s 241ms/step - loss: 0.0341 - accuracy: 0.9897 - val_loss: 0.3059 - val_accuracy: 0.9062\n",
            "Epoch 13/30\n",
            "442/442 [==============================] - 107s 241ms/step - loss: 0.0556 - accuracy: 0.9825 - val_loss: 0.2488 - val_accuracy: 0.9323\n",
            "Epoch 14/30\n",
            "442/442 [==============================] - 106s 241ms/step - loss: 0.0567 - accuracy: 0.9811 - val_loss: 0.4850 - val_accuracy: 0.8666\n",
            "Epoch 15/30\n",
            "442/442 [==============================] - 107s 241ms/step - loss: 0.0415 - accuracy: 0.9877 - val_loss: 0.3616 - val_accuracy: 0.9150\n",
            "Epoch 16/30\n",
            "442/442 [==============================] - 107s 241ms/step - loss: 0.0401 - accuracy: 0.9889 - val_loss: 0.3995 - val_accuracy: 0.9008\n",
            "Epoch 17/30\n",
            "442/442 [==============================] - 107s 241ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.3207 - val_accuracy: 0.9011\n",
            "Epoch 18/30\n",
            "442/442 [==============================] - 106s 241ms/step - loss: 0.0373 - accuracy: 0.9861 - val_loss: 0.9755 - val_accuracy: 0.7527\n",
            "Epoch 19/30\n",
            "442/442 [==============================] - 107s 241ms/step - loss: 0.0410 - accuracy: 0.9871 - val_loss: 0.2528 - val_accuracy: 0.9269\n",
            "Epoch 20/30\n",
            "442/442 [==============================] - 106s 241ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.3966 - val_accuracy: 0.9048\n",
            "Epoch 21/30\n",
            "442/442 [==============================] - 106s 241ms/step - loss: 0.0350 - accuracy: 0.9914 - val_loss: 0.3704 - val_accuracy: 0.9091\n",
            "Epoch 22/30\n",
            "442/442 [==============================] - 106s 241ms/step - loss: 0.0302 - accuracy: 0.9907 - val_loss: 0.3872 - val_accuracy: 0.8986\n",
            "Epoch 23/30\n",
            "442/442 [==============================] - 106s 241ms/step - loss: 0.0544 - accuracy: 0.9849 - val_loss: 0.1652 - val_accuracy: 0.9516\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Model/RN50_1/cp/assets\n",
            "Epoch 24/30\n",
            "442/442 [==============================] - 107s 241ms/step - loss: 0.0345 - accuracy: 0.9895 - val_loss: 0.1324 - val_accuracy: 0.9629\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Model/RN50_1/cp/assets\n",
            "Epoch 25/30\n",
            "442/442 [==============================] - 107s 242ms/step - loss: 0.0241 - accuracy: 0.9925 - val_loss: 2.8530 - val_accuracy: 0.3827\n",
            "Epoch 26/30\n",
            "442/442 [==============================] - 107s 243ms/step - loss: 0.0265 - accuracy: 0.9934 - val_loss: 0.1948 - val_accuracy: 0.9561\n",
            "Epoch 27/30\n",
            "442/442 [==============================] - 107s 242ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.2593 - val_accuracy: 0.9442\n",
            "Epoch 28/30\n",
            "442/442 [==============================] - 107s 242ms/step - loss: 0.0453 - accuracy: 0.9856 - val_loss: 0.3550 - val_accuracy: 0.9034\n",
            "Epoch 29/30\n",
            "442/442 [==============================] - 107s 242ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 0.1705 - val_accuracy: 0.9629\n",
            "Epoch 30/30\n",
            "442/442 [==============================] - 107s 242ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 0.1620 - val_accuracy: 0.9601\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Model/RN50_1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9k_cw8hi-Cn"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Model/RN50_1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ7Ji0l3TJEe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}