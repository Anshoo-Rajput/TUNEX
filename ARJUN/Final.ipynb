{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "model = tf.keras.models.load_model(\"/home/arjun/DM/face.h5\")\n",
    "# EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\"neutral\"]\n",
    "EMOTIONS=[\"angry\",\n",
    "        \"disgust\",\n",
    "        \"fear\",\n",
    "        \"happy\",\n",
    "        \"neutral\",\n",
    "        \"sad\",\n",
    "        \"surprise\"]\n",
    "# EMOTIONS = [\"afraid\",\"angry\",\"disgust\",\"happy\",\"neutral\",\"sad\",\"surprised\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(ima):\n",
    "    IMG_SIZE = 48        # image size\n",
    "    img_array = cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    img_array=img_array/255.0  \n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1,IMG_SIZE, IMG_SIZE,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear\n"
     ]
    }
   ],
   "source": [
    "image=cv2.imread(\"images.jpeg\")\n",
    "# faces = face_cascade.detectMultiScale(image, 1.3, 5)\n",
    "# faces = sorted(faces, reverse=True, key = lambda x: (x[2]-x[0]) *(x[3]-x[1]))[0]\n",
    "# (x,y,w,h)=faces\n",
    "# roi = image[y-40:y+h+40, x:x+w]\n",
    "prediction = model.predict([prepare(image)])\n",
    "preds = prediction[0]\n",
    "label = EMOTIONS[preds.argmax()]\n",
    "print(label)\n",
    "# image = cv2.rectangle(image,(x,y-40),(x+w,y+h+40),(255,0,0),2)\n",
    "cv2.imshow(\"image\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /tmp/pip-req-build-ms668fyv/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-7cd22085257e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     print(img.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m540\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m960\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /tmp/pip-req-build-ms668fyv/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(\"/home/arjun/DM/1.mp4\")\n",
    "# cap=cv2.VideoCapture(0)\n",
    "result = cv2.VideoWriter('1testface.avi',cv2.VideoWriter_fourcc(*'MJPG'), 30, (540, 960)) \n",
    "while True:\n",
    "    ret, img=cap.read()\n",
    "#     print(img.shape)\n",
    "    img = cv2.resize(img, (540, 960))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    canvas = np.zeros((256,256,3), dtype=\"uint8\")\n",
    "    frameclone=img\n",
    "    try:\n",
    "        faces = sorted(faces, reverse=True, key = lambda x: (x[2]-x[0]) *(x[3]-x[1]))[0]\n",
    "        (x,y,w,h)=faces\n",
    "        img = cv2.rectangle(img,(x,y-20),(x+w,y+h),(255,0,0),2)\n",
    "        roi = img[y-20:y+h, x:x+w]\n",
    "        cv2.imshow('img2',roi)\n",
    "        prediction = (model.predict([prepare(roi)]))\n",
    "        preds = prediction[0]\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "        for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n",
    "            text = \"{}: {:.2f}%\".format(emotion, prob*100)\n",
    "            w = int(prob*300)\n",
    "            cv2.rectangle(canvas, (7, (i*35)+5), (w, (i*35)+35),(0,0,255), -1)\n",
    "            cv2.putText(canvas, text, (10, (i*35) +23), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,255,255), 2)\n",
    "            cv2.imshow(\"Probabilities\", canvas)\n",
    "        \n",
    "        cv2.putText(img,label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "        result.write(img)\n",
    "    except:\n",
    "        pass\n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(1)\n",
    "    if cv2.waitKey(1) & cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on static Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry\n",
      "Right 25 Wrong 24\n",
      "disgust\n",
      "Right 33 Wrong 16\n",
      "fear\n",
      "Right 18 Wrong 31\n",
      "happy\n",
      "Right 36 Wrong 13\n",
      "neutral\n",
      "Right 33 Wrong 16\n",
      "sad\n",
      "Right 31 Wrong 18\n",
      "surprise\n",
      "Right 40 Wrong 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for j in range(0,7):\n",
    "    right_count=0\n",
    "    wrong_count=0\n",
    "    for i in range(1,50):\n",
    "#         try:\n",
    "            img=cv2.imread(\"/home/arjun/DM/Face/validation/\"+str(j)+\"/\"+str(i)+\".jpg\")\n",
    "    #         cv2.imshow(\"image\",img)\n",
    "    #         cv2.waitKey(0)\n",
    "    #         cv2.destroyAllWindows() \n",
    "#             faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "#             print(faces)\n",
    "#             faces = sorted(faces, reverse=True, key = lambda x: (x[2]-x[0]) *(x[3]-x[1]))[0]\n",
    "#             (x,y,w,h)=faces\n",
    "#             roi = image[y-20:y+h, x:x+w]\n",
    "            pr=model.predict([prepare(img)])\n",
    "            preds=pr[0]\n",
    "            label = EMOTIONS[preds.argmax()]\n",
    "            if(label==EMOTIONS[j]):\n",
    "                right_count+=1\n",
    "            else:\n",
    "                wrong_count+=1\n",
    "#         except:\n",
    "#             pass\n",
    "    print(EMOTIONS[j])\n",
    "    print(\"Right \"+str(right_count)+\" Wrong \"+str(wrong_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angry\n",
    "Right 20 Wrong 29\n",
    "disgust\n",
    "Right 30 Wrong 19\n",
    "fear\n",
    "Right 23 Wrong 26\n",
    "happy\n",
    "Right 40 Wrong 9\n",
    "neutral\n",
    "Right 26 Wrong 23\n",
    "sad\n",
    "Right 32 Wrong 17\n",
    "surprise\n",
    "Right 34 Wrong 15\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
