{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "from PIL import Image, ImageEnhance, ImageDraw \n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI(frame):\n",
    "    #enhancer = ImageEnhance.Contrast(frame)\n",
    "    #img = enhancer.enhance(0.7)\n",
    "    face_classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_RGB2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.1, 5)\n",
    "    x=0\n",
    "    y=0\n",
    "    w=0\n",
    "    h=0\n",
    "    max_area = 0\n",
    "    for face in faces:\n",
    "        x_t, y_t, w_t, h_t = face\n",
    "        if w_t*h_t>max_area:\n",
    "            max_area = w_t*h_t\n",
    "            x,y,w,h = face\n",
    "    #print(faces)\n",
    "    \n",
    "    return x,y,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.models.load_model(\"model_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = {\n",
    "    '0' : 'Afraid',\n",
    "    '1' : 'Angry',\n",
    "    '2' : 'Disgust',\n",
    "    '3' : 'Happy',\n",
    "    '4' : 'Nervous',\n",
    "    '5' : 'Sad',\n",
    "    '6' : 'Surprise'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def using_cam():\n",
    "    cap = cv.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        #cv.imshow(\"Input\",frame)\n",
    "        #frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        x,y,w,h = ROI(frame)\n",
    "        if x==0 and y==0 and w==0:\n",
    "            continue\n",
    "        #cv.rectangle(frame, (x,y), (x+w, y+h), (127, 0, 255), 2)\n",
    "        croped_image = frame[x:x+w, y:y+h]\n",
    "        croped_image = cv.cvtColor(croped_image, cv.COLOR_BGR2RGB)\n",
    "        cv.imshow('ROI', croped_image)\n",
    "        if(cv.waitKey(2) == 13 & 0xFF):\n",
    "            break\n",
    "        \n",
    "        \n",
    "        img = Image.fromarray(frame)\n",
    "        img.save(\"Pic.jpg\")\n",
    "        img = keras.preprocessing.image.load_img(\n",
    "            'Pic.jpg', target_size=(128, 128)\n",
    "        )\n",
    "        img_array = keras.preprocessing.image.img_to_array(img)\n",
    "        img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "        predictions = model.predict(img_array)\n",
    "        score = tf.nn.softmax(predictions[0])\n",
    "        \n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        fontScale = 2\n",
    "        thickness = 4\n",
    "        color = (255, 0, 0)\n",
    "        pos = (x, y+h)\n",
    "        image = cv.putText(frame, emotion[str(np.argmax(score))], pos, font, fontScale, color, thickness, cv.LINE_AA)\n",
    "        \n",
    "        \n",
    "        #print(emotion[str(np.argmax(score))])\n",
    "        cv.imshow(\"Final\", image)\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_cam()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
