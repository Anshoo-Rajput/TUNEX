# Integrating Emotion Detection with Song Recomendation

> The file `feedOut.ipynb` contains the code for outputting the final emotion, after iterating through all frames in the video input given.

> Music is played as the final output in the file `finalIntegrate.ipynb`. The final emotion is recognised on the video input, which then maps to a defined genre. After settling on to one genre, a song, at random, is chosen from finalized genre folder, and then it is played.

> The video input used here in `finalIntegrate.ipynb` is `deeps.mp4` which outputs the happy sentiment.

#### 
#### The final code that captures the live feed for 10 seconds and plays a song, all in continuous loop, is [finalVideoTest.ipynb](finalVideoTest.ipynb)
