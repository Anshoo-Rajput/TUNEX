{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from IPython.display import Audio \n",
    "from IPython.core.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import os\n",
    "import eyed3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(ima):\n",
    "    IMG_SIZE = 48        # image size\n",
    "    img_array = cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    img_array=img_array/255.0  \n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1,IMG_SIZE, IMG_SIZE,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTIONS = [\"afraid\",\"angry\",\"disgust\",\"happy\",\"neutral\",\"sad\",\"surprised\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = {\n",
    "    '0' : 'Afraid',\n",
    "    '1' : 'Angry',\n",
    "    '2' : 'Disgust',\n",
    "    '3' : 'Happy',\n",
    "    '4' : 'Neutral',\n",
    "    '5' : 'Sad',\n",
    "    '6' : 'Surprise'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videocap():\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    emotion_count = [0,0,0,0,0,0,0]\n",
    "    start = time.time()\n",
    "    while (time.time()-start < 10):\n",
    "        ret, img=cap.read()\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 8)\n",
    "        canvas = np.zeros((256,256,3), dtype=\"uint8\")\n",
    "        frameclone=img\n",
    "        try:\n",
    "            faces = sorted(faces, reverse=True, key = lambda x: (x[2]-x[0]) *(x[3]-x[1]))[0]\n",
    "            (x,y,w,h)=faces\n",
    "            img = cv2.rectangle(img,(x,y),(x+w,y+h),(220,40,50),2)\n",
    "            roi = img[y:y+h, x:x+w]\n",
    "\n",
    "            prediction = (model.predict([prepare(roi)]))\n",
    "            preds = prediction[0]\n",
    "            label = EMOTIONS[preds.argmax()]\n",
    "            emotion_count[preds.argmax()]+=1\n",
    "            \n",
    "            cv2.rectangle(img,(x,y+h+10),(x+w,y+h+70),(220,40,50),-2)\n",
    "            cv2.putText(img,label, (x+10, y+h+50), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (225, 225, 225), 3)\n",
    "            #cv2.putText(img,label, (x+w, y+h-40), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (220, 40, 50), 3)\n",
    "            #result.write(img)\n",
    "        except:\n",
    "            pass\n",
    "        cv2.imshow('img',img)\n",
    "\n",
    "        if cv2.waitKey(1) & cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    emo = emotion[str(np.argmax(emotion_count))]\n",
    "    \n",
    "    return emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EMOTIONS = [\"afraid\",\"angry\",\"disgust\",\"happy\",\"neutral\",\"sad\",\"surprised\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emotion = {\n",
    "#    '0' : 'Afraid',\n",
    "#    '1' : 'Angry',\n",
    "#    '2' : 'Disgust',\n",
    "#    '3' : 'Happy',\n",
    "#    '4' : 'Neutral',\n",
    "#    '5' : 'Sad',\n",
    "#    '6' : 'Surprise'\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def videoemotion(directory):\n",
    "#    cap=cv2.VideoCapture(directory)\n",
    "#\n",
    "#    while cap.isOpened():\n",
    "#        ret, img=cap.read()\n",
    "#        if not ret:\n",
    "#            break\n",
    "#\n",
    "#        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#        faces = face_cascade.detectMultiScale(gray, 1.3, 8)\n",
    "#        canvas = np.zeros((256,256,3), dtype=\"uint8\")\n",
    "#        frameclone=img\n",
    "#        try:\n",
    "#            faces = sorted(faces, reverse=True, key = lambda x: (x[2]-x[0]) *(x[3]-x[1]))[0]\n",
    "#            (x,y,w,h)=faces\n",
    "#            img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "#            roi = img[y:y+h, x:x+w]\n",
    "#\n",
    "#            prediction = (model.predict([prepare(roi)]))\n",
    "#            preds = prediction[0]\n",
    "#            label = EMOTIONS[preds.argmax()]\n",
    "#            emotion_count[preds.argmax()]+=1\n",
    "#        except:\n",
    "#            pass\n",
    "#\n",
    "#    cap.release()\n",
    "#    cv2.destroyAllWindows()\n",
    "#    \n",
    "#    emo = emotion[str(np.argmax(emotion_count))]\n",
    "#    \n",
    "#    return emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afraid: Hip Hop\n",
    "### Angry: Rock, Metal\n",
    "### Disgust: Hip Hop, Jazz\n",
    "### Happy: Pop, Disco\n",
    "### Neutral: Reggae, Classical\n",
    "### Sad: Blues, Country, Classical\n",
    "### Surprise: Disco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def egmap(emotionout):\n",
    "    \n",
    "    afraidlist = [\"hiphop\"]\n",
    "    angrylist = [\"rock\", \"metal\"]\n",
    "    disgustlist = [\"hiphop\", \"jazz\"]\n",
    "    happylist = [\"pop\", \"disco\"]\n",
    "    neutrallist = [\"reggae\", \"classical\"]\n",
    "    sadlist = [\"blues\", \"classical\", \"country\"]\n",
    "    surprisedlist = [\"disco\"]\n",
    "    \n",
    "    if emotionout is 'Afraid':\n",
    "        genrechosen = random.choice(afraidlist)\n",
    "    if emotionout is 'Angry':\n",
    "        genrechosen = random.choice(angrylist)\n",
    "    if emotionout is 'Disgust':\n",
    "        genrechosen = random.choice(disgustlist)\n",
    "    if emotionout is 'Happy':\n",
    "        genrechosen = random.choice(happylist)\n",
    "    if emotionout is 'Neutral':\n",
    "        genrechosen = random.choice(neutrallist)\n",
    "    if emotionout is 'Sad':\n",
    "        genrechosen = random.choice(sadlist)\n",
    "    if emotionout is 'Surprise':\n",
    "        genrechosen = random.choice(surprisedlist)\n",
    "    \n",
    "    dirt = \"Genre/\"+genrechosen\n",
    "    songchosen = random.choice(os.listdir(dirt))\n",
    "    diro = \"Genre/\"+genrechosen+\"/\"+songchosen        \n",
    "        \n",
    "    return diro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(emotionout):\n",
    "    print(\"Here's a song for you :\")\n",
    "    song = egmap(emotionout)\n",
    "\n",
    "    audiofile = eyed3.load(song)\n",
    "\n",
    "    Artist = audiofile.tag.artist\n",
    "    Album = audiofile.tag.album\n",
    "    Title = audiofile.tag.title\n",
    "    \n",
    "    print(Title+\" by \"+Artist)\n",
    "    display(Audio(song, autoplay=True, rate=8000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory = \"record.avi\"\n",
    "#emotionout = videoemotion()\n",
    "#print(\"Your Recognised emotion is \"+ emotionout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommend(emotionout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tunex():\n",
    "    for i in range(0, 4):\n",
    "        emotionout = videocap() \n",
    "        print(\"Your Recognised emotion is \"+ emotionout)\n",
    "        recommend(emotionout)\n",
    "        time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUNEX\n",
    "### Tunes for Expressions\n",
    "> by team AI/ML - DRISHTI\n",
    "###### Maintain an emotion for 10 seconds and wait for the music to play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
