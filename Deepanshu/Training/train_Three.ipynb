{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_Three.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjunparmar/TUNEX/blob/main/Deepanshu/Training/train_Three.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5elDpIX9kwg"
      },
      "source": [
        "import os\r\n",
        "import sys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWhT45kc8l-J",
        "outputId": "79fa7d07-d736-42e1-cfe2-d9175593970e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAb77yZ9fzMG"
      },
      "source": [
        "data_Dir = \"/content/drive/MyDrive/main\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from keras.preprocessing import image_dataset_from_directory\r\n",
        "from keras.preprocessing import image\r\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qxr-leg991d"
      },
      "source": [
        "height = 224\r\n",
        "width = 224\r\n",
        "batch_Size = 32"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g10FuoiW99nD",
        "outputId": "791c2b23-0432-42b4-80bc-537968521a93"
      },
      "source": [
        "train_Data = image_dataset_from_directory(\r\n",
        "    data_Dir,\r\n",
        "    labels=\"inferred\",\r\n",
        "    label_mode=\"categorical\",\r\n",
        "    batch_size=32,\r\n",
        "    image_size=(height, width),\r\n",
        "    shuffle=True,\r\n",
        "    seed = 20,\r\n",
        "    validation_split = 0.2,\r\n",
        "    subset = \"training\",\r\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 17676 files belonging to 7 classes.\n",
            "Using 14141 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwQ1NeeI99UM",
        "outputId": "23fc7855-b7b5-453d-8fc2-757cb6766f8e"
      },
      "source": [
        "valid_Data = image_dataset_from_directory(\r\n",
        "    data_Dir,\r\n",
        "    labels=\"inferred\",\r\n",
        "    label_mode=\"categorical\",\r\n",
        "    batch_size=32,\r\n",
        "    image_size=(height, width),\r\n",
        "    shuffle=True,\r\n",
        "    seed = 20,\r\n",
        "    validation_split = 0.2,\r\n",
        "    subset = \"validation\",\r\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 17676 files belonging to 7 classes.\n",
            "Using 3535 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6sU6Z-y98_L"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "train_Tuned = train_Data.cache().prefetch(buffer_size=AUTOTUNE)\r\n",
        "valid_Tuned = valid_Data.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMwh1jRk98vS"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\r\n",
        "from keras.layers.experimental.preprocessing import Rescaling\r\n",
        "from keras.losses import categorical_crossentropy\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\r\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TPwFzXx98hI"
      },
      "source": [
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(Rescaling(1./255))\r\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding = 'same', input_shape=(height, width, 1)))\r\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding = 'same', input_shape=(height, width, 1)))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\r\n",
        "model.add(Dropout(0.3))\r\n",
        "\r\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same'))\r\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\r\n",
        "#model.add(BatchNormalization())\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\r\n",
        "model.add(Dropout(0.3))\r\n",
        "\r\n",
        "#model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same'))\r\n",
        "#model.add(Conv2D(128, (3, 3), activation='relu'))\r\n",
        "#model.add(BatchNormalization())\r\n",
        "#model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\r\n",
        "#model.add(Dropout(0.3))\r\n",
        "\r\n",
        "#model.add(Conv2D(256, (3, 3), activation='relu', padding = 'same'))\r\n",
        "#model.add(Conv2D(256, (3, 3), activation='relu'))\r\n",
        "#model.add(BatchNormalization())\r\n",
        "#model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\r\n",
        "#model.add(Dropout(0.3))\r\n",
        "\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation='relu'))\r\n",
        "#model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.5))\r\n",
        "\r\n",
        "model.add(Dense(64, activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.3))\r\n",
        "\r\n",
        "#model.add(Dense(16, activation='relu'))\r\n",
        "#model.add(BatchNormalization())\r\n",
        "#model.add(Dropout(0.2))\r\n",
        "\r\n",
        "model.add(Dense(7, activation='softmax'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NMeRIkN98Tw"
      },
      "source": [
        "model.compile(\r\n",
        "    optimizer = Adam(lr = 0.001),\r\n",
        "    loss = \"categorical_crossentropy\",\r\n",
        "    metrics = ['accuracy'],\r\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvBGvZRW98Cm"
      },
      "source": [
        "early_Stop = EarlyStopping(\r\n",
        "    monitor=\"val_loss\",\r\n",
        "    min_delta=0,\r\n",
        "    patience=3,\r\n",
        "    verbose=1,\r\n",
        "    restore_best_weights=True,\r\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgPsJlyt97Sr"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\r\n",
        "    '/gdrive/MyDrive/model_One.h5',\r\n",
        "    monitor=\"val_accuracy\",\r\n",
        "    verbose=1,\r\n",
        "    save_best_only=True,\r\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-CUHQkM-ofi"
      },
      "source": [
        "callbacks = [early_Stop]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOPAzhDH-oE8",
        "outputId": "d44c70f2-c1cd-420d-b399-48b5445b9a8d"
      },
      "source": [
        "model.fit(\r\n",
        "    train_Tuned,\r\n",
        "    epochs = 30,\r\n",
        "    validation_data = valid_Tuned,\r\n",
        "    callbacks = callbacks,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "442/442 [==============================] - 3791s 8s/step - loss: 2.4706 - accuracy: 0.1490 - val_loss: 1.9436 - val_accuracy: 0.1389\n",
            "Epoch 2/30\n",
            "442/442 [==============================] - 563s 1s/step - loss: 2.0453 - accuracy: 0.1548 - val_loss: 1.9225 - val_accuracy: 0.1901\n",
            "Epoch 3/30\n",
            "442/442 [==============================] - 565s 1s/step - loss: 1.9795 - accuracy: 0.1730 - val_loss: 1.8935 - val_accuracy: 0.2164\n",
            "Epoch 4/30\n",
            "442/442 [==============================] - 559s 1s/step - loss: 1.9097 - accuracy: 0.2074 - val_loss: 1.8940 - val_accuracy: 0.2062\n",
            "Epoch 5/30\n",
            "442/442 [==============================] - 564s 1s/step - loss: 1.7853 - accuracy: 0.2806 - val_loss: 1.4403 - val_accuracy: 0.5010\n",
            "Epoch 6/30\n",
            "442/442 [==============================] - 565s 1s/step - loss: 1.3947 - accuracy: 0.4712 - val_loss: 0.9998 - val_accuracy: 0.6504\n",
            "Epoch 7/30\n",
            "442/442 [==============================] - 568s 1s/step - loss: 1.0455 - accuracy: 0.6045 - val_loss: 0.7744 - val_accuracy: 0.7216\n",
            "Epoch 8/30\n",
            "442/442 [==============================] - 594s 1s/step - loss: 0.8386 - accuracy: 0.6782 - val_loss: 0.6806 - val_accuracy: 0.7584\n",
            "Epoch 9/30\n",
            "442/442 [==============================] - 563s 1s/step - loss: 0.6648 - accuracy: 0.7442 - val_loss: 0.5993 - val_accuracy: 0.7810\n",
            "Epoch 10/30\n",
            "442/442 [==============================] - 572s 1s/step - loss: 0.5471 - accuracy: 0.8001 - val_loss: 0.4103 - val_accuracy: 0.8546\n",
            "Epoch 11/30\n",
            "442/442 [==============================] - 626s 1s/step - loss: 0.4347 - accuracy: 0.8441 - val_loss: 0.3161 - val_accuracy: 0.9013\n",
            "Epoch 12/30\n",
            "361/442 [=======================>......] - ETA: 1:53 - loss: 0.3506 - accuracy: 0.8741"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}