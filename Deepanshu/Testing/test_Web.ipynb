{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_Web.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjunparmar/TUNEX/blob/main/Deepanshu/Testing/test_Web.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5elDpIX9kwg"
      },
      "source": [
        "import os\r\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWhT45kc8l-J"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "from keras.preprocessing.image import img_to_array\r\n",
        "from keras.models import load_model\r\n",
        "import imutils\r\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qxr-leg991d"
      },
      "source": [
        "cascade = cv2.CascadeClassifier('/content/drive/MyDrive/haarcascade_frontalface_default.xml')\r\n",
        "model = load_model(\"/content/drive/MyDrive/model_Four.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g10FuoiW99nD"
      },
      "source": [
        "classes = ['Afraid', 'Angry', 'Disgust', 'Happy', 'Neutral', 'Sad', 'Suprised']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OxdUDcK6xUX"
      },
      "source": [
        "!pip install ffmpeg-python\r\n",
        "\r\n",
        "\r\n",
        "from IPython.display import HTML, Javascript, display\r\n",
        "from google.colab.output import eval_js\r\n",
        "from base64 import b64decode\r\n",
        "import numpy as np\r\n",
        "import io\r\n",
        "import ffmpeg\r\n",
        "\r\n",
        "video_file_test = '/content/drive/MyDrive/Video/osy_test.mp4' \r\n",
        "  \r\n",
        "\r\n",
        "VIDEO_HTML = \"\"\"\r\n",
        "<script>\r\n",
        "var my_div = document.createElement(\"DIV\");\r\n",
        "var my_p = document.createElement(\"P\");\r\n",
        "var my_btn = document.createElement(\"BUTTON\");\r\n",
        "var my_btn_txt = document.createTextNode(\"Press to start recording\");\r\n",
        "my_btn.appendChild(my_btn_txt);\r\n",
        "my_div.appendChild(my_btn);\r\n",
        "document.body.appendChild(my_div);\r\n",
        "var base64data = 0;\r\n",
        "var reader;\r\n",
        "var recorder, videoStream;\r\n",
        "var recordButton = my_btn;\r\n",
        "var handleSuccess = function(stream) {\r\n",
        "  videoStream = stream;\r\n",
        "  var options = {  \r\n",
        "    mimeType : 'video/webm;codecs=vp9'  \r\n",
        "  };            \r\n",
        "  recorder = new MediaRecorder(stream, options);\r\n",
        "  recorder.ondataavailable = function(e) {            \r\n",
        "    var url = URL.createObjectURL(e.data);\r\n",
        "    var preview = document.createElement('video');\r\n",
        "    preview.controls = true;\r\n",
        "    preview.src = url;\r\n",
        "    document.body.appendChild(preview);\r\n",
        "    reader = new FileReader();\r\n",
        "    reader.readAsDataURL(e.data); \r\n",
        "    reader.onloadend = function() {\r\n",
        "      base64data = reader.result;\r\n",
        "    }\r\n",
        "  };\r\n",
        "  recorder.start();\r\n",
        "  };\r\n",
        "recordButton.innerText = \"Recording... press to stop\";\r\n",
        "navigator.mediaDevices.getUserMedia({video: true}).then(handleSuccess);\r\n",
        "function toggleRecording() {\r\n",
        "  if (recorder && recorder.state == \"recording\") {\r\n",
        "      recorder.stop();\r\n",
        "      videoStream.getVideoTracks()[0].stop();\r\n",
        "      recordButton.innerText = \"Saving the recording... Please wait!\"\r\n",
        "  }\r\n",
        "}\r\n",
        "function sleep(ms) {\r\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\r\n",
        "}\r\n",
        "var data = new Promise(resolve=>{\r\n",
        "recordButton.onclick = ()=>{\r\n",
        "toggleRecording()\r\n",
        "sleep(2000).then(() => {\r\n",
        "  // wait 2000ms for the data to be available\r\n",
        "  resolve(base64data.toString())\r\n",
        "});\r\n",
        "}\r\n",
        "});\r\n",
        "      \r\n",
        "</script>\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def start_webcam():\r\n",
        "  js = Javascript('''\r\n",
        "    async function startWebcam() {\r\n",
        "      const div = document.createElement('div');\r\n",
        "      const video = document.createElement('video');\r\n",
        "      video.style.display = 'block';\r\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\r\n",
        "      document.body.appendChild(div);\r\n",
        "      div.appendChild(video);\r\n",
        "      video.srcObject = stream;\r\n",
        "      await video.play();\r\n",
        "      // Resize the output to fit the video element.\r\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\r\n",
        "      \r\n",
        "      return;\r\n",
        "    }\r\n",
        "    ''')\r\n",
        "  \r\n",
        "  display(js)\r\n",
        "  data = eval_js('startWebcam()')\r\n",
        "  \r\n",
        "    \r\n",
        "start_webcam()\r\n",
        "\r\n",
        "def get_video():\r\n",
        "  display(HTML(VIDEO_HTML))\r\n",
        "  data = eval_js(\"data\")\r\n",
        "  binary = b64decode(data.split(',')[1])\r\n",
        "  \r\n",
        "  return binary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS5lSdDK7T-j"
      },
      "source": [
        "videofile = get_video()\r\n",
        "with open(video_file_test, 'wb') as f:\r\n",
        "  f.write(videofile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwQ1NeeI99UM"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\r\n",
        "\r\n",
        "capture = cv2.VideoCapture(video_file_test)\r\n",
        "\r\n",
        "while capture.isOpened():\r\n",
        "\r\n",
        "    check, image = capture.read()\r\n",
        "    image = imutils.resize(image, width=400)\r\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n",
        "    face  = cascade.detectMultiScale(gray, 1.3, 8)\r\n",
        "\r\n",
        "    for (x, y, w, h) in face:\r\n",
        "        cv2.rectangle(image, (x, y), ((x + w), (y + h)), (110, 240, 4), 2)\r\n",
        "        cv2.rectangle(image, (x, y-30), ((x + w), y), (110, 240, 4), -2)\r\n",
        "        roi = gray[y:y+h, x:x+w]\r\n",
        "        roi = cv2.resize(roi, (48,48), interpolation=cv2.INTER_AREA)\r\n",
        "        roi = roi.astype(\"float\")/255.0\r\n",
        "        roi = img_to_array(roi)\r\n",
        "        roi = tf.expand_dims(roi, axis=0)\r\n",
        "\r\n",
        "        emotion = model.predict(roi)[0]\r\n",
        "        label = classes[emotion.argmax()]\r\n",
        "        \r\n",
        "        cv2.putText(image, label, (x+20, y-10), cv2.FONT_HERSHEY_DUPLEX, 0.6, (255,255,255), 2)\r\n",
        "    else:\r\n",
        "        cv2.putText(image, 'No Face Detected', (20, 10), cv2.FONT_HERSHEY_DUPLEX, 0.6, (255,255,255), 2)\r\n",
        "\r\n",
        "    cv2_imshow(image)\r\n",
        "\r\n",
        "    if cv2.waitKey(1) in {27, 32, 13}:\r\n",
        "        break\r\n",
        "\r\n",
        "capture.release()\r\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}